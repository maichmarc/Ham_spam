{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac542e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MARK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MARK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MARK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.components.data_transformation import AvgWord2VecTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65827254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                      Ok lar... Joking wif u oni...   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/PROJECTS/Spam_ham/artifact/new_raw.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b8a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0f0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(df['message'], window=5, min_count=2)\n",
    "avg = AvgWord2VecTransformer(model=model, vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b21de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output vector array: (5572, 100)\n"
     ]
    }
   ],
   "source": [
    "x_arr = avg.transform(df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930de966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08156593, -0.01654109, -0.12217434, ...,  0.09169908,\n",
       "        -0.31980577, -0.13389412],\n",
       "       [ 0.06254326, -0.01261468, -0.07486455, ...,  0.10102341,\n",
       "        -0.31125668, -0.12232729],\n",
       "       [ 0.11181074, -0.04265167, -0.12990525, ...,  0.06824829,\n",
       "        -0.3601083 , -0.16806786],\n",
       "       ...,\n",
       "       [ 0.07210715, -0.01019281, -0.09696254, ...,  0.07362017,\n",
       "        -0.32245046, -0.13669261],\n",
       "       [ 0.07512356,  0.00430616, -0.09476101, ...,  0.08072476,\n",
       "        -0.33262372, -0.15627548],\n",
       "       [ 0.10356133, -0.04289059, -0.10813075, ...,  0.08960694,\n",
       "        -0.33230397, -0.18057072]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d472a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5c648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "                ('Avg_w2v',AvgWord2VecTransformer(model=model, vector_size=100), 'message')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c478739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "365d362e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['go', 'jurong', 'point', 'crazy', 'available'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ok', 'lar', 'joking', 'wif', 'oni']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['free', 'entry', 'wkly', 'comp', 'win', 'fa',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['dun', 'say', 'early', 'hor', 'already', 'say']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['nah', 'think', 'go', 'usf', 'life', 'around'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>['nd', 'time', 'tried', 'contact', 'pound', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>['going', 'esplanade', 'fr', 'home']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>['pity', 'mood', 'that', 'so', 'any', 'suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>['guy', 'bitching', 'acted', 'like', 'interest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>['rofl', 'true', 'name']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "0     ['go', 'jurong', 'point', 'crazy', 'available'...\n",
       "1                 ['ok', 'lar', 'joking', 'wif', 'oni']\n",
       "2     ['free', 'entry', 'wkly', 'comp', 'win', 'fa',...\n",
       "3      ['dun', 'say', 'early', 'hor', 'already', 'say']\n",
       "4     ['nah', 'think', 'go', 'usf', 'life', 'around'...\n",
       "...                                                 ...\n",
       "5567  ['nd', 'time', 'tried', 'contact', 'pound', 'p...\n",
       "5568               ['going', 'esplanade', 'fr', 'home']\n",
       "5569  ['pity', 'mood', 'that', 'so', 'any', 'suggest...\n",
       "5570  ['guy', 'bitching', 'acted', 'like', 'interest...\n",
       "5571                           ['rofl', 'true', 'name']\n",
       "\n",
       "[5572 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d883a59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x_array = \u001b[43mpreprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m x_array\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PROJECTS\\Spam_ham\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PROJECTS\\Spam_ham\\venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1060\u001b[39m, in \u001b[36mColumnTransformer.transform\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m   1034\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform X separately by each transformer, concatenate results.\u001b[39;00m\n\u001b[32m   1035\u001b[39m \n\u001b[32m   1036\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1057\u001b[39m \u001b[33;03m    sparse matrices.\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1059\u001b[39m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m X = _check_X(X)\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# If ColumnTransformer is fit using a dataframe, and now a dataframe is\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# passed to be transformed, we select columns by name instead. This\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# enables the user to pass X at transform time with extra columns which\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[38;5;66;03m# were not present in fit time, and the order of the columns doesn't\u001b[39;00m\n\u001b[32m   1067\u001b[39m \u001b[38;5;66;03m# matter.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\PROJECTS\\Spam_ham\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1757\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "x_array = preprocessor.transform(X)\n",
    "x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0dab646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of output vector array: (5572, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.08156593, -0.01654109, -0.12217434, ...,  0.09169908,\n",
       "        -0.31980577, -0.13389412],\n",
       "       [ 0.06254326, -0.01261468, -0.07486455, ...,  0.10102341,\n",
       "        -0.31125668, -0.12232729],\n",
       "       [ 0.11181074, -0.04265167, -0.12990525, ...,  0.06824829,\n",
       "        -0.3601083 , -0.16806786],\n",
       "       ...,\n",
       "       [ 0.07210715, -0.01019281, -0.09696254, ...,  0.07362017,\n",
       "        -0.32245046, -0.13669261],\n",
       "       [ 0.07512356,  0.00430616, -0.09476101, ...,  0.08072476,\n",
       "        -0.33262372, -0.15627548],\n",
       "       [ 0.10356133, -0.04289059, -0.10813075, ...,  0.08960694,\n",
       "        -0.33230397, -0.18057072]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_X = preprocessor.fit_transform(X)\n",
    "array_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cc6260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MARK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MARK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MARK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.components.data_transformation import DataTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28924ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "5572\n",
      "['go', 'jurong', 'point', 'crazy', 'available', 'bugis', 'great', 'world', 'la', 'buffet', 'cine', 'got', 'amore', 'wat']\n",
      "shape of output vector array: (5572, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "X_array shape: (5572, 100)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "<class 'numpy.ndarray'>\n",
      "y_array shape: (5572,)\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "data_transformation = DataTransformation()\n",
    "\n",
    "X_arr, y_arr,_ = data_transformation.initiate_data_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6ac3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bdfc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(b'\\x01\\x00\\x00\\x00', byteorder='little')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7986c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = b'\\x01\\x00\\x00\\x00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0449644",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = int.from_bytes(eds, byteorder='little')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b30dcd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370d1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
